{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "24c23264a495e1bfafd09abe8aac9138d80825b4e42f16f3a074c20b0dc913f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import shutil\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Google_Image = \\\n",
    "    'https://www.google.com/search?site=&tbm=isch&source=hp&biw=1873&bih=990&'\n",
    "\n",
    "# The User-Agent request header contains a characteristic string \n",
    "# that allows the network protocol peers to identify the application type, \n",
    "# operating system, and software version of the requesting software user agent.\n",
    "# needed for google search\n",
    "u_agnt = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "    'Accept-Encoding': 'none',\n",
    "    'Accept-Language': 'en-US,en;q=0.8',\n",
    "    'Connection': 'keep-alive',\n",
    "} #write: 'my user agent' in browser to get your browser user agent details\n",
    "\n",
    "Image_Folder = 'Images_1'\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(Image_Folder):\n",
    "        os.mkdir(Image_Folder)\n",
    "    download_images()\n",
    "\n",
    "def download_images():\n",
    "    data = input('Enter your search keyword: ')\n",
    "    num_images = int(input('Enter the number of images you want: '))\n",
    "    \n",
    "    print('Searching Images....')\n",
    "    \n",
    "    search_url = Google_Image + 'q=' + data #'q=' because its a query\n",
    "    \n",
    "    # request url, without u_agnt the permission gets denied\n",
    "    response = requests.get(search_url, headers=u_agnt)\n",
    "    html = response.text #To get actual result i.e. to read the html data in text mode\n",
    "    \n",
    "    # find all img where class='rg_i Q4LuWd'\n",
    "    b_soup = BeautifulSoup(html, 'html.parser') #html.parser is used to parse/extract features from HTML files\n",
    "    results = b_soup.findAll('img', {'class': 'rg_i Q4LuWd'})\n",
    "    \n",
    "    #extract the links of requested number of images with 'data-src' attribute and appended those links to a list 'imagelinks'\n",
    "    #allow to continue the loop in case query fails for non-data-src attributes\n",
    "    count = 0\n",
    "    imagelinks= []\n",
    "    for res in results:\n",
    "        try:\n",
    "            link = res['data-src']\n",
    "            imagelinks.append(link)\n",
    "            count = count + 1\n",
    "            if (count >= num_images):\n",
    "                break\n",
    "            \n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    print(f'Found {len(imagelinks)} images')\n",
    "    print('Start downloading...')\n",
    "\n",
    "    for i, imagelink in enumerate(imagelinks):\n",
    "        # open each image link and save the file\n",
    "        response = requests.get(imagelink)\n",
    "        \n",
    "        imagename = Image_Folder + '/' + data + str(i+1) + '.jpg'\n",
    "        with open(imagename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "\n",
    "    print('Download Completed!')\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Google_Image = \\\n",
    "    'https://www.google.com/search?site=&tbm=isch&source=hp&biw=1873&bih=990&'\n",
    "u_agnt = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.83 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "    'Accept-Encoding': 'none',\n",
    "    'Accept-Language': 'en-US,en;q=0.8',\n",
    "    'Connection': 'keep-alive',\n",
    "} \n",
    "Image_Folder = 'Images_1'\n",
    "def download_images():\n",
    "    data = input('Enter your search keyword: ')\n",
    "    num_images = int(input('Enter the number of images you want: '))    \n",
    "    print('Searching Images....')    \n",
    "    search_url = Google_Image + 'q=' + data\n",
    "    response = requests.get(search_url, headers=u_agnt)\n",
    "    html = response.text\n",
    "    b_soup = BeautifulSoup(html, 'html.parser')\n",
    "    results = b_soup.findAll('img', {'class': 'rg_i Q4LuWd'})\n",
    "    count = 0\n",
    "    imagelinks= []\n",
    "    for res in results:\n",
    "        try:\n",
    "            link = res['data-src']\n",
    "            imagelinks.append(link)\n",
    "            count = count + 1\n",
    "            if (count >= num_images):\n",
    "                break            \n",
    "        except KeyError:\n",
    "            continue    \n",
    "    print(f'Found {len(imagelinks)} images')\n",
    "    print('Start downloading...')\n",
    "    for i, imagelink in enumerate(imagelinks):\n",
    "        response = requests.get(imagelink)        \n",
    "        imagename = Image_Folder + '/' + data + str(i+1) + '.jpg'\n",
    "        with open(imagename, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "    print('Download Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(Image_Folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Searching Images....\n",
      "Found 5 images\n",
      "Start downloading...\n",
      "Download Completed!\n"
     ]
    }
   ],
   "source": [
    "download_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}